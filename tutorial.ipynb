{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Introduction to Graph Diffusion Model in the Discrete Space\n",
    "\n",
    "\n",
    "Diffusion Model \n",
    "\n",
    "Graph Diffusion Model \n",
    "\n",
    "The **aims** of this tutorial are as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Installation and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch_geometric.utils import to_dense_adj, to_dense_batch, remove_self_loops, to_undirected\n",
    "from torchmetrics import Metric, MeanSquaredError\n",
    "from torch import Tensor\n",
    "import math\n",
    "from torch.nn.modules.dropout import Dropout\n",
    "from torch.nn.modules.linear import Linear\n",
    "from torch.nn.modules.normalization import LayerNorm\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "import os\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation \n",
    "\n",
    "In the first section of the tutorial, we only focus on the generation of graph topology which is the main novelty of the graph diffusion model. Later, we will apply the graph diffusion model on the molecular graph characterized with different atom and edge types, displaying the most popular application of graph generation model.\n",
    "\n",
    "### Examining the Raw Graph Topology\n",
    "\n",
    "The adjacency matrix $A \\in \\mathbb R^{n\\times n}$ where $n$ is the number of nodes in the graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]]) \n",
      " The shape of graph: torch.Size([150, 150])\n"
     ]
    }
   ],
   "source": [
    "dataset_path = 'datasets/raw_graph_data'\n",
    "dataset = torch.load(os.path.join(dataset_path, 'data.pt'))\n",
    "graph = dataset[0]\n",
    "print(graph, '\\n The shape of graph:', graph.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,  ..., 149, 149, 149],\n",
       "        [  0, 143, 145,  ..., 130, 136, 149]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.nonzero().t()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Data Objects and Data Loader with Pytorch Geometric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_object(data, mol=False):\n",
    "    if isinstance(data, torch.Tensor) and not mol: \n",
    "        n_nodes = data.shape[0] \n",
    "        edge_index = data.nonzero().t() \n",
    "        # each edge has uniform feature [0,1] as one-hot encoding\n",
    "        edge_attr = torch.tensor([[0, 1] for _ in range(edge_index.shape[1])]) \n",
    "\n",
    "        edge_index, edge_attr = to_undirected(edge_index, edge_attr, n_nodes, reduce = 'mean')\n",
    "        edge_index, edge_attr = remove_self_loops(edge_index, edge_attr)\n",
    "\n",
    "        # each node has uniform feature 1 \n",
    "        x = torch.ones((n_nodes, 1))\n",
    "        # empty global feature\n",
    "        y = torch.empty(1, 0)\n",
    "\n",
    "        return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "\n",
    "    else:\n",
    "        raise ValueError('Data type not supported') \n",
    "\n",
    "def load_dataset(dataname, batch_size=1):\n",
    "    data_path = os.path.join('datasets', dataname)\n",
    "    if not os.path.exists(os.path.join('datasets',dataname, 'train.pt')):\n",
    "        raise ValueError('Dataset not found. Please run split_dataset first.')\n",
    "    else:\n",
    "        train_data = [create_data_object(_) for _ in torch.load(os.path.join(data_path, 'train.pt'))]\n",
    "        val_data = [create_data_object(_) for _ in torch.load(os.path.join(data_path, 'val.pt'))]\n",
    "        test_data = [create_data_object(_) for _ in torch.load(os.path.join(data_path, 'test.pt'))]\n",
    "\n",
    "        train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)  \n",
    "        val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "        test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "def split_dataset(dataname):\n",
    "    if not os.path.exists(os.path.join('datasets',dataname, 'train.pt')):\n",
    "\n",
    "        torch.manual_seed(0)\n",
    "        n = len(dataset)\n",
    "        indices = torch.randperm(n)\n",
    "        # 80% train, 10% validation, 10% test\n",
    "        train_indices = indices[:int(0.8 * n)]\n",
    "        val_indices = indices[int(0.8 * n):int(0.9 * n)]\n",
    "        test_indices = indices[int(0.9 * n):]\n",
    "\n",
    "        train_data = [dataset[_] for _ in train_indices]\n",
    "        val_data = [dataset[_] for _ in val_indices]\n",
    "        test_data = [dataset[_] for _ in test_indices]\n",
    "\n",
    "        # save the train, valid, test, indices\n",
    "        torch.save(train_indices, os.path.join(dataset_path, 'train_indices.pt'))\n",
    "        torch.save(val_indices, os.path.join(dataset_path, 'val_indices.pt'))  \n",
    "        torch.save(test_indices, os.path.join(dataset_path, 'test_indices.pt'))\n",
    "\n",
    "        # save the train, valid, test data\n",
    "        torch.save(train_data, os.path.join(dataset_path, 'train.pt'))\n",
    "        torch.save(val_data, os.path.join(dataset_path, 'val.pt'))\n",
    "        torch.save(test_data, os.path.join(dataset_path, 'test.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_dataset(dataname, batch_size):\n",
    "    train_loader, val_loader, test_loader = load_dataset(dataname, batch_size)\n",
    "\n",
    "    n_nodes = node_counts(1000, train_loader, val_loader)\n",
    "    node_types = torch.tensor([1]) \n",
    "    edge_types = edge_counts(train_loader)\n",
    "    \n",
    "    num_classes = len(node_types)\n",
    "    max_n_nodes = len(n_nodes) - 1\n",
    "    nodes_dist = DistributionNodes(n_nodes)\n",
    "    \n",
    "    data_loaders = {'train': train_loader, 'val': val_loader, 'test': test_loader}\n",
    "\n",
    "    return data_loaders, num_classes, max_n_nodes, nodes_dist, edge_types, node_types, n_nodes\n",
    "\n",
    "\n",
    "def node_counts():\n",
    "    pass \n",
    "\n",
    "def edge_counts():\n",
    "    pass \n",
    "\n",
    "def DistributionNodes():\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([600, 1])\n",
      "torch.Size([2, 2352])\n",
      "torch.Size([2352, 2])\n",
      "torch.Size([4, 0])\n"
     ]
    }
   ],
   "source": [
    "train_loader, valid_loader, test_loader = load_dataset('raw_graph_data', batch_size=4)\n",
    "for i, batch in enumerate(train_loader):\n",
    "    print(batch.x.shape)\n",
    "    print(batch.edge_index.shape)\n",
    "    print(batch.edge_attr.shape)\n",
    "    print(batch.y.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure the node and edge matrices in a batch to be consistent during the training and sampling, we create a **PlaceHolder** to store $X, E, y$ which is able to mask the actual node in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlaceHolder:\n",
    "    def __init__(self, X, E, y):\n",
    "        self.X = X\n",
    "        self.E = E\n",
    "        self.y = y\n",
    "\n",
    "    def type_as(self, x: torch.Tensor):\n",
    "        \"\"\" Changes the device and dtype of X, E, y. \"\"\"\n",
    "        self.X = self.X.type_as(x)\n",
    "        self.E = self.E.type_as(x)\n",
    "        self.y = self.y.type_as(x)\n",
    "        return self\n",
    "\n",
    "    def mask(self, node_mask, collapse=False):\n",
    "        x_mask = node_mask.unsqueeze(-1)          # bs, n, 1\n",
    "        e_mask1 = x_mask.unsqueeze(2)             # bs, n, 1, 1\n",
    "        e_mask2 = x_mask.unsqueeze(1)             # bs, 1, n, 1\n",
    "\n",
    "        if collapse:\n",
    "            self.X = torch.argmax(self.X, dim=-1)\n",
    "            self.E = torch.argmax(self.E, dim=-1)\n",
    "\n",
    "            self.X[node_mask == 0] = - 1\n",
    "            self.E[(e_mask1 * e_mask2).squeeze(-1) == 0] = - 1\n",
    "        else:\n",
    "            self.X = self.X * x_mask\n",
    "            self.E = self.E * e_mask1 * e_mask2\n",
    "            assert torch.allclose(self.E, torch.transpose(self.E, 1, 2))\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_no_edge(E):\n",
    "    assert len(E.shape) == 4\n",
    "    if E.shape[-1] == 0:\n",
    "        return E\n",
    "    no_edge = torch.sum(E, dim=3) == 0\n",
    "    first_elt = E[:, :, :, 0]\n",
    "    first_elt[no_edge] = 1\n",
    "    E[:, :, :, 0] = first_elt\n",
    "    diag = torch.eye(E.shape[1], dtype=torch.bool).unsqueeze(0).expand(E.shape[0], -1, -1)\n",
    "    E[diag] = 0\n",
    "    return E\n",
    "\n",
    "def to_dense(x, edge_index, edge_attr, batch):\n",
    "    X, node_mask = to_dense_batch(x=x, batch=batch)\n",
    "    # node_mask = node_mask.float()\n",
    "    edge_index, edge_attr = remove_self_loops(edge_index, edge_attr)\n",
    "    \n",
    "    # TODO: carefully check if setting node_mask as a bool breaks the continuous case\n",
    "    max_num_nodes = X.size(1)\n",
    "    E = to_dense_adj(edge_index=edge_index, batch=batch, edge_attr=edge_attr, max_num_nodes=max_num_nodes)\n",
    "    print('check edge_index ................', E.dtype) \n",
    "    E = encode_no_edge(E)\n",
    "\n",
    "    return PlaceHolder(X=X, E=E, y=None), node_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurartion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diffusion Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise Scheduler (Cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscreteUniformTransition:\n",
    "    def __init__(self, x_classes: int, e_classes: int, y_classes: int):\n",
    "        self.X_classes = x_classes\n",
    "        self.E_classes = e_classes\n",
    "        self.y_classes = y_classes\n",
    "        self.u_x = torch.ones(1, self.X_classes, self.X_classes)\n",
    "        if self.X_classes > 0:\n",
    "            self.u_x = self.u_x / self.X_classes\n",
    "\n",
    "        self.u_e = torch.ones(1, self.E_classes, self.E_classes)\n",
    "        if self.E_classes > 0:\n",
    "            self.u_e = self.u_e / self.E_classes\n",
    "\n",
    "        self.u_y = torch.ones(1, self.y_classes, self.y_classes)\n",
    "        if self.y_classes > 0:\n",
    "            self.u_y = self.u_y / self.y_classes\n",
    "\n",
    "    def get_Qt(self, beta_t, device):\n",
    "        \"\"\" Returns one-step transition matrices for X and E, from step t - 1 to step t.\n",
    "        Qt = (1 - beta_t) * I + beta_t / K\n",
    "\n",
    "        beta_t: (bs)                         noise level between 0 and 1\n",
    "        returns: qx (bs, dx, dx), qe (bs, de, de), qy (bs, dy, dy).\n",
    "        \"\"\"\n",
    "        beta_t = beta_t.unsqueeze(1)\n",
    "        beta_t = beta_t.to(device)\n",
    "        self.u_x = self.u_x.to(device)\n",
    "        self.u_e = self.u_e.to(device)\n",
    "        self.u_y = self.u_y.to(device)\n",
    "\n",
    "        q_x = beta_t * self.u_x + (1 - beta_t) * torch.eye(self.X_classes, device=device).unsqueeze(0)\n",
    "        q_e = beta_t * self.u_e + (1 - beta_t) * torch.eye(self.E_classes, device=device).unsqueeze(0)\n",
    "        q_y = beta_t * self.u_y + (1 - beta_t) * torch.eye(self.y_classes, device=device).unsqueeze(0)\n",
    "\n",
    "        return PlaceHolder(X=q_x, E=q_e, y=q_y)\n",
    "\n",
    "    def get_Qt_bar(self, alpha_bar_t, device):\n",
    "        \"\"\" Returns t-step transition matrices for X and E, from step 0 to step t.\n",
    "        Qt = prod(1 - beta_t) * I + (1 - prod(1 - beta_t)) / K\n",
    "\n",
    "        alpha_bar_t: (bs)         Product of the (1 - beta_t) for each time step from 0 to t.\n",
    "        returns: qx (bs, dx, dx), qe (bs, de, de), qy (bs, dy, dy).\n",
    "        \"\"\"\n",
    "        alpha_bar_t = alpha_bar_t.unsqueeze(1)\n",
    "        alpha_bar_t = alpha_bar_t.to(device)\n",
    "        self.u_x = self.u_x.to(device)\n",
    "        self.u_e = self.u_e.to(device)\n",
    "        self.u_y = self.u_y.to(device)\n",
    "\n",
    "        q_x = alpha_bar_t * torch.eye(self.X_classes, device=device).unsqueeze(0) + (1 - alpha_bar_t) * self.u_x\n",
    "        q_e = alpha_bar_t * torch.eye(self.E_classes, device=device).unsqueeze(0) + (1 - alpha_bar_t) * self.u_e\n",
    "        q_y = alpha_bar_t * torch.eye(self.y_classes, device=device).unsqueeze(0) + (1 - alpha_bar_t) * self.u_y\n",
    "\n",
    "        return PlaceHolder(X=q_x, E=q_e, y=q_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_beta_schedule_discrete(timesteps, s=0.008):\n",
    "    \"\"\" Cosine schedule as proposed in https://openreview.net/forum?id=-NEXDKk8gZ. \"\"\"\n",
    "    steps = timesteps + 2\n",
    "    x = np.linspace(0, steps, steps)\n",
    "\n",
    "    alphas_cumprod = np.cos(0.5 * np.pi * ((x / steps) + s) / (1 + s)) ** 2\n",
    "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "    alphas = (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "    betas = 1 - alphas\n",
    "    return betas.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredefinedNoiseScheduleDiscrete(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Predefined noise schedule. Essentially creates a lookup array for predefined (non-learned) noise schedules.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, noise_schedule, timesteps):\n",
    "        super(PredefinedNoiseScheduleDiscrete, self).__init__()\n",
    "        self.timesteps = timesteps\n",
    "\n",
    "        if noise_schedule == 'cosine':\n",
    "            betas = cosine_beta_schedule_discrete(timesteps)\n",
    "        else:\n",
    "            raise NotImplementedError(noise_schedule)\n",
    "\n",
    "        self.register_buffer('betas', torch.from_numpy(betas).float())\n",
    "        self.alphas = 1 - torch.clamp(self.betas, min=0, max=0.9999)\n",
    "\n",
    "        log_alpha = torch.log(self.alphas)\n",
    "        log_alpha_bar = torch.cumsum(log_alpha, dim=0)\n",
    "        self.alphas_bar = torch.exp(log_alpha_bar)\n",
    "        # print(f\"[Noise schedule: {noise_schedule}] alpha_bar:\", self.alphas_bar)\n",
    "\n",
    "    def forward(self, t_normalized=None, t_int=None):\n",
    "        assert int(t_normalized is None) + int(t_int is None) == 1\n",
    "        if t_int is None:\n",
    "            t_int = torch.round(t_normalized * self.timesteps)\n",
    "        return self.betas[t_int.long()]\n",
    "\n",
    "    def get_alpha_bar(self, t_normalized=None, t_int=None):\n",
    "        assert int(t_normalized is None) + int(t_int is None) == 1\n",
    "        if t_int is None:\n",
    "            t_int = torch.round(t_normalized * self.timesteps)\n",
    "        return self.alphas_bar.to(t_int.device)[t_int.long()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_noise(self, X, E, y, node_mask, augment = False):\n",
    "    \"\"\" Sample noise and apply it to the data. \"\"\"\n",
    "\n",
    "    # Sample a timestep t.\n",
    "    # When evaluating, the loss for t=0 is computed separately\n",
    "    if not augment:\n",
    "        lowest_t = 0 if self.training else 1\n",
    "        t_int = torch.randint(lowest_t, self.T + 1, size=(X.size(0), 1), device=X.device).float()  # (bs, 1)\n",
    "        s_int = t_int - 1\n",
    "\n",
    "        t_float = t_int / self.T\n",
    "        s_float = s_int / self.T\n",
    "    else:\n",
    "        t_int = self.aug_steps * torch.ones(X.size(0), 1, device = X.device).float()\n",
    "        s_int = t_int - 1\n",
    "\n",
    "        t_float = t_int / self.aug_steps\n",
    "        s_float = s_int / self.aug_steps\n",
    "\n",
    "    # beta_t and alpha_s_bar are used for denoising/loss computation\n",
    "    beta_t = self.noise_schedule(t_normalized=t_float)                         # (bs, 1)\n",
    "    alpha_s_bar = self.noise_schedule.get_alpha_bar(t_normalized=s_float)      # (bs, 1)\n",
    "    alpha_t_bar = self.noise_schedule.get_alpha_bar(t_normalized=t_float)      # (bs, 1)\n",
    "\n",
    "    Qtb = self.transition_model.get_Qt_bar(alpha_t_bar, device=self.device)  # (bs, dx_in, dx_out), (bs, de_in, de_out)\n",
    "    assert (abs(Qtb.X.sum(dim=2) - 1.) < 1e-4).all(), Qtb.X.sum(dim=2) - 1\n",
    "    assert (abs(Qtb.E.sum(dim=2) - 1.) < 1e-4).all()\n",
    "\n",
    "    # Compute transition probabilities\n",
    "    probX = X @ Qtb.X  # (bs, n, dx_out)\n",
    "    probE = E @ Qtb.E.unsqueeze(1)  # (bs, n, n, de_out)\n",
    "\n",
    "    sampled_t = diffusion_utils.sample_discrete_features(probX=probX, probE=probE, node_mask=node_mask)\n",
    "\n",
    "    X_t = F.one_hot(sampled_t.X, num_classes=self.Xdim_output)\n",
    "    E_t = F.one_hot(sampled_t.E, num_classes=self.Edim_output)\n",
    "    assert (X.shape == X_t.shape) and (E.shape == E_t.shape)\n",
    "\n",
    "    z_t = PlaceHolder(X=X_t, E=E_t, y=y).type_as(X_t).mask(node_mask)\n",
    "\n",
    "    noisy_data = {'t_int': t_int, 't': t_float, 'beta_t': beta_t, 'alpha_s_bar': alpha_s_bar,\n",
    "                    'alpha_t_bar': alpha_t_bar, 'X_t': z_t.X, 'E_t': z_t.E, 'y_t': z_t.y, 'node_mask': node_mask}\n",
    "    return noisy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SumExceptBatchKL(Metric):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.add_state('total_value', default=torch.tensor(0.), dist_reduce_fx=\"sum\")\n",
    "        self.add_state('total_samples', default=torch.tensor(0.), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, p, q) -> None:\n",
    "        self.total_value += F.kl_div(q, p, reduction='sum')\n",
    "        self.total_samples += p.size(0)\n",
    "\n",
    "    def compute(self):\n",
    "        return self.total_value / self.total_samples\n",
    "    \n",
    "class SumExceptBatchMetric(Metric):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.add_state('total_value', default=torch.tensor(0.), dist_reduce_fx=\"sum\")\n",
    "        self.add_state('total_samples', default=torch.tensor(0.), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, values) -> None:\n",
    "        self.total_value += torch.sum(values)\n",
    "        self.total_samples += values.shape[0]\n",
    "\n",
    "    def compute(self):\n",
    "        return self.total_value / self.total_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyMetric(Metric):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.add_state('total_ce', default=torch.tensor(0.), dist_reduce_fx=\"sum\")\n",
    "        self.add_state('total_samples', default=torch.tensor(0.), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, preds: Tensor, target: Tensor) -> None:\n",
    "        \"\"\" Update state with predictions and targets.\n",
    "            preds: Predictions from model   (bs * n, d) or (bs * n * n, d)\n",
    "            target: Ground truth values     (bs * n, d) or (bs * n * n, d). \"\"\"\n",
    "        target = torch.argmax(target, dim=-1)\n",
    "        output = F.cross_entropy(preds, target, reduction='sum')\n",
    "        self.total_ce += output\n",
    "        self.total_samples += preds.size(0)\n",
    "\n",
    "    def compute(self):\n",
    "        return self.total_ce / self.total_samples\n",
    "\n",
    "\n",
    "class TrainLossDiscrete(nn.Module):\n",
    "    \"\"\" Train with Cross entropy\"\"\"\n",
    "    def __init__(self, lambda_train):\n",
    "        super().__init__()\n",
    "        self.node_loss = CrossEntropyMetric()\n",
    "        self.edge_loss = CrossEntropyMetric()\n",
    "        self.y_loss = CrossEntropyMetric()\n",
    "        self.lambda_train = lambda_train\n",
    "\n",
    "    def forward(self, masked_pred_X, masked_pred_E, pred_y, true_X, true_E, true_y, log: bool):\n",
    "        \"\"\" Compute train metrics\n",
    "        masked_pred_X : tensor -- (bs, n, dx)\n",
    "        masked_pred_E : tensor -- (bs, n, n, de)\n",
    "        pred_y : tensor -- (bs, )\n",
    "        true_X : tensor -- (bs, n, dx)\n",
    "        true_E : tensor -- (bs, n, n, de)\n",
    "        true_y : tensor -- (bs, )\n",
    "        log : boolean. \"\"\"\n",
    "        true_X = torch.reshape(true_X, (-1, true_X.size(-1)))  # (bs * n, dx)\n",
    "        true_E = torch.reshape(true_E, (-1, true_E.size(-1)))  # (bs * n * n, de)\n",
    "        masked_pred_X = torch.reshape(masked_pred_X, (-1, masked_pred_X.size(-1)))  # (bs * n, dx)\n",
    "        masked_pred_E = torch.reshape(masked_pred_E, (-1, masked_pred_E.size(-1)))   # (bs * n * n, de)\n",
    "\n",
    "        # Remove masked rows\n",
    "        mask_X = (true_X != 0.).any(dim=-1)\n",
    "        mask_E = (true_E != 0.).any(dim=-1)\n",
    "\n",
    "        flat_true_X = true_X[mask_X, :]\n",
    "        flat_pred_X = masked_pred_X[mask_X, :]\n",
    "\n",
    "        flat_true_E = true_E[mask_E, :]\n",
    "        flat_pred_E = masked_pred_E[mask_E, :]\n",
    "\n",
    "        loss_X = self.node_loss(flat_pred_X, flat_true_X) if true_X.numel() > 0 else 0.0\n",
    "        loss_E = self.edge_loss(flat_pred_E, flat_true_E) if true_E.numel() > 0 else 0.0\n",
    "        loss_y = self.y_loss(pred_y, true_y) if true_y.numel() > 0 else 0.0\n",
    "\n",
    "        # if log:\n",
    "        #     to_log = {\"train_loss/batch_CE\": (loss_X + loss_E + loss_y).detach(),\n",
    "        #               \"train_loss/X_CE\": self.node_loss.compute() if true_X.numel() > 0 else -1,\n",
    "        #               \"train_loss/E_CE\": self.edge_loss.compute() if true_E.numel() > 0 else -1,\n",
    "        #               \"train_loss/y_CE\": self.y_loss.compute() if true_y.numel() > 0 else -1}\n",
    "        #     if wandb.run:\n",
    "        #         wandb.log(to_log, commit=True)\n",
    "        \n",
    "        return loss_X + self.lambda_train[0] * loss_E + self.lambda_train[1] * loss_y\n",
    "\n",
    "    def reset(self):\n",
    "        for metric in [self.node_loss, self.edge_loss, self.y_loss]:\n",
    "            metric.reset()\n",
    "\n",
    "    def log_epoch_metrics(self):\n",
    "        epoch_node_loss = self.node_loss.compute() if self.node_loss.total_samples > 0 else -1\n",
    "        epoch_edge_loss = self.edge_loss.compute() if self.edge_loss.total_samples > 0 else -1\n",
    "        epoch_y_loss = self.train_y_loss.compute() if self.y_loss.total_samples > 0 else -1\n",
    "\n",
    "        to_log = {\"train_epoch/x_CE\": epoch_node_loss,\n",
    "                  \"train_epoch/E_CE\": epoch_edge_loss,\n",
    "                  \"train_epoch/y_CE\": epoch_y_loss}\n",
    "        if wandb.run:\n",
    "            wandb.log(to_log, commit=False)\n",
    "\n",
    "        return to_log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Transformer $\\phi_{\\theta}$: the Denoising Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xtoy(nn.Module):\n",
    "    def __init__(self, dx, dy):\n",
    "        \"\"\" Map node features to global features \"\"\"\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(4 * dx, dy)\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\" X: bs, n, dx. \"\"\"\n",
    "        m = X.mean(dim=1)\n",
    "        mi = X.min(dim=1)[0]\n",
    "        ma = X.max(dim=1)[0]\n",
    "        std = X.std(dim=1)\n",
    "        z = torch.hstack((m, mi, ma, std))\n",
    "        out = self.lin(z)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Etoy(nn.Module):\n",
    "    def __init__(self, d, dy):\n",
    "        \"\"\" Map edge features to global features. \"\"\"\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(4 * d, dy)\n",
    "\n",
    "    def forward(self, E):\n",
    "        \"\"\" E: bs, n, n, de\n",
    "            Features relative to the diagonal of E could potentially be added.\n",
    "        \"\"\"\n",
    "        m = E.mean(dim=(1, 2))\n",
    "        mi = E.min(dim=2)[0].min(dim=1)[0]\n",
    "        ma = E.max(dim=2)[0].max(dim=1)[0]\n",
    "        std = torch.std(E, dim=(1, 2))\n",
    "        z = torch.hstack((m, mi, ma, std))\n",
    "        out = self.lin(z)\n",
    "        return out\n",
    "\n",
    "\n",
    "def masked_softmax(x, mask, **kwargs):\n",
    "    if mask.sum() == 0:\n",
    "        return x\n",
    "    x_masked = x.clone()\n",
    "    x_masked[mask == 0] = -float(\"inf\")\n",
    "    return torch.softmax(x_masked, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XEyTransformerLayer(nn.Module):\n",
    "    \"\"\" Transformer that updates node, edge and global features\n",
    "        d_x: node features\n",
    "        d_e: edge features\n",
    "        dz : global features\n",
    "        n_head: the number of heads in the multi_head_attention\n",
    "        dim_feedforward: the dimension of the feedforward network model after self-attention\n",
    "        dropout: dropout probablility. 0 to disable\n",
    "        layer_norm_eps: eps value in layer normalizations.\n",
    "    \"\"\"\n",
    "    def __init__(self, dx: int, de: int, dy: int, n_head: int, dim_ffX: int = 2048,\n",
    "                 dim_ffE: int = 128, dim_ffy: int = 2048, dropout: float = 0.1,\n",
    "                 layer_norm_eps: float = 1e-5, device=None, dtype=None) -> None:\n",
    "        kw = {'device': device, 'dtype': dtype}\n",
    "        super().__init__()\n",
    "\n",
    "        self.self_attn = NodeEdgeBlock(dx, de, dy, n_head, **kw)\n",
    "\n",
    "        self.linX1 = Linear(dx, dim_ffX, **kw)\n",
    "        self.linX2 = Linear(dim_ffX, dx, **kw)\n",
    "        self.normX1 = LayerNorm(dx, eps=layer_norm_eps, **kw)\n",
    "        self.normX2 = LayerNorm(dx, eps=layer_norm_eps, **kw)\n",
    "        self.dropoutX1 = Dropout(dropout)\n",
    "        self.dropoutX2 = Dropout(dropout)\n",
    "        self.dropoutX3 = Dropout(dropout)\n",
    "\n",
    "        self.linE1 = Linear(de, dim_ffE, **kw)\n",
    "        self.linE2 = Linear(dim_ffE, de, **kw)\n",
    "        self.normE1 = LayerNorm(de, eps=layer_norm_eps, **kw)\n",
    "        self.normE2 = LayerNorm(de, eps=layer_norm_eps, **kw)\n",
    "        self.dropoutE1 = Dropout(dropout)\n",
    "        self.dropoutE2 = Dropout(dropout)\n",
    "        self.dropoutE3 = Dropout(dropout)\n",
    "\n",
    "        self.lin_y1 = Linear(dy, dim_ffy, **kw)\n",
    "        self.lin_y2 = Linear(dim_ffy, dy, **kw)\n",
    "        self.norm_y1 = LayerNorm(dy, eps=layer_norm_eps, **kw)\n",
    "        self.norm_y2 = LayerNorm(dy, eps=layer_norm_eps, **kw)\n",
    "        self.dropout_y1 = Dropout(dropout)\n",
    "        self.dropout_y2 = Dropout(dropout)\n",
    "        self.dropout_y3 = Dropout(dropout)\n",
    "\n",
    "        self.activation = F.relu\n",
    "\n",
    "    def forward(self, X: Tensor, E: Tensor, y, node_mask: Tensor):\n",
    "        \"\"\" Pass the input through the encoder layer.\n",
    "            X: (bs, n, d)\n",
    "            E: (bs, n, n, d)\n",
    "            y: (bs, dy)\n",
    "            node_mask: (bs, n) Mask for the src keys per batch (optional)\n",
    "            Output: newX, newE, new_y with the same shape.\n",
    "        \"\"\"\n",
    "\n",
    "        newX, newE, new_y = self.self_attn(X, E, y, node_mask=node_mask)\n",
    "\n",
    "        newX_d = self.dropoutX1(newX)\n",
    "        X = self.normX1(X + newX_d)\n",
    "\n",
    "        newE_d = self.dropoutE1(newE)\n",
    "        E = self.normE1(E + newE_d)\n",
    "\n",
    "        new_y_d = self.dropout_y1(new_y)\n",
    "        y = self.norm_y1(y + new_y_d)\n",
    "\n",
    "        ff_outputX = self.linX2(self.dropoutX2(self.activation(self.linX1(X))))\n",
    "        ff_outputX = self.dropoutX3(ff_outputX)\n",
    "        X = self.normX2(X + ff_outputX)\n",
    "\n",
    "        ff_outputE = self.linE2(self.dropoutE2(self.activation(self.linE1(E))))\n",
    "        ff_outputE = self.dropoutE3(ff_outputE)\n",
    "        E = self.normE2(E + ff_outputE)\n",
    "\n",
    "        ff_output_y = self.lin_y2(self.dropout_y2(self.activation(self.lin_y1(y))))\n",
    "        ff_output_y = self.dropout_y3(ff_output_y)\n",
    "        y = self.norm_y2(y + ff_output_y)\n",
    "\n",
    "        return X, E, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeEdgeBlock(nn.Module):\n",
    "    \"\"\" Self attention layer that also updates the representations on the edges. \"\"\"\n",
    "    def __init__(self, dx, de, dy, n_head, **kwargs):\n",
    "        super().__init__()\n",
    "        assert dx % n_head == 0, f\"dx: {dx} -- nhead: {n_head}\"\n",
    "        self.dx = dx\n",
    "        self.de = de\n",
    "        self.dy = dy\n",
    "        self.df = int(dx / n_head)\n",
    "        self.n_head = n_head\n",
    "\n",
    "        # Attention\n",
    "        self.q = Linear(dx, dx)\n",
    "        self.k = Linear(dx, dx)\n",
    "        self.v = Linear(dx, dx)\n",
    "\n",
    "        # FiLM E to X\n",
    "        self.e_add = Linear(de, dx)\n",
    "        self.e_mul = Linear(de, dx)\n",
    "\n",
    "        # FiLM y to E\n",
    "        self.y_e_mul = Linear(dy, dx)           # Warning: here it's dx and not de\n",
    "        self.y_e_add = Linear(dy, dx)\n",
    "\n",
    "        # FiLM y to X\n",
    "        self.y_x_mul = Linear(dy, dx)\n",
    "        self.y_x_add = Linear(dy, dx)\n",
    "\n",
    "        # Process y\n",
    "        self.y_y = Linear(dy, dy)\n",
    "        self.x_y = Xtoy(dx, dy)\n",
    "        self.e_y = Etoy(de, dy)\n",
    "\n",
    "        # Output layers\n",
    "        self.x_out = Linear(dx, dx)\n",
    "        self.e_out = Linear(dx, de)\n",
    "        self.y_out = nn.Sequential(nn.Linear(dy, dy), nn.ReLU(), nn.Linear(dy, dy))\n",
    "\n",
    "    def forward(self, X, E, y, node_mask):\n",
    "        \"\"\"\n",
    "        :param X: bs, n, d        node features\n",
    "        :param E: bs, n, n, d     edge features\n",
    "        :param y: bs, dz           global features\n",
    "        :param node_mask: bs, n\n",
    "        :return: newX, newE, new_y with the same shape.\n",
    "        \"\"\"\n",
    "        bs, n, _ = X.shape\n",
    "        x_mask = node_mask.unsqueeze(-1)        # bs, n, 1\n",
    "        e_mask1 = x_mask.unsqueeze(2)           # bs, n, 1, 1\n",
    "        e_mask2 = x_mask.unsqueeze(1)           # bs, 1, n, 1\n",
    "\n",
    "        # 1. Map X to keys and queries\n",
    "        Q = self.q(X) * x_mask           # (bs, n, dx)\n",
    "        K = self.k(X) * x_mask           # (bs, n, dx)\n",
    "        diffusion_utils.assert_correctly_masked(Q, x_mask)\n",
    "        # 2. Reshape to (bs, n, n_head, df) with dx = n_head * df\n",
    "\n",
    "        Q = Q.reshape((Q.size(0), Q.size(1), self.n_head, self.df))\n",
    "        K = K.reshape((K.size(0), K.size(1), self.n_head, self.df))\n",
    "\n",
    "        Q = Q.unsqueeze(2)                              # (bs, 1, n, n_head, df)\n",
    "        K = K.unsqueeze(1)                              # (bs, n, 1, n head, df)\n",
    "\n",
    "        # Compute unnormalized attentions. Y is (bs, n, n, n_head, df)\n",
    "        Y = Q * K\n",
    "        Y = Y / math.sqrt(Y.size(-1))\n",
    "        diffusion_utils.assert_correctly_masked(Y, (e_mask1 * e_mask2).unsqueeze(-1))\n",
    "\n",
    "        E1 = self.e_mul(E) * e_mask1 * e_mask2                        # bs, n, n, dx\n",
    "        E1 = E1.reshape((E.size(0), E.size(1), E.size(2), self.n_head, self.df))\n",
    "\n",
    "        E2 = self.e_add(E) * e_mask1 * e_mask2                        # bs, n, n, dx\n",
    "        E2 = E2.reshape((E.size(0), E.size(1), E.size(2), self.n_head, self.df))\n",
    "\n",
    "        # Incorporate edge features to the self attention scores.\n",
    "        Y = Y * (E1 + 1) + E2                  # (bs, n, n, n_head, df)\n",
    "\n",
    "        # Incorporate y to E\n",
    "        newE = Y.flatten(start_dim=3)                      # bs, n, n, dx\n",
    "        ye1 = self.y_e_add(y).unsqueeze(1).unsqueeze(1)  # bs, 1, 1, de\n",
    "        ye2 = self.y_e_mul(y).unsqueeze(1).unsqueeze(1)\n",
    "        newE = ye1 + (ye2 + 1) * newE\n",
    "\n",
    "        # Output E\n",
    "        newE = self.e_out(newE) * e_mask1 * e_mask2      # bs, n, n, de\n",
    "        diffusion_utils.assert_correctly_masked(newE, e_mask1 * e_mask2)\n",
    "\n",
    "        # Compute attentions. attn is still (bs, n, n, n_head, df)\n",
    "        softmax_mask = e_mask2.expand(-1, n, -1, self.n_head)    # bs, 1, n, 1\n",
    "        attn = masked_softmax(Y, softmax_mask, dim=2)  # bs, n, n, n_head\n",
    "\n",
    "        V = self.v(X) * x_mask                        # bs, n, dx\n",
    "        V = V.reshape((V.size(0), V.size(1), self.n_head, self.df))\n",
    "        V = V.unsqueeze(1)                                     # (bs, 1, n, n_head, df)\n",
    "\n",
    "        # Compute weighted values\n",
    "        weighted_V = attn * V\n",
    "        weighted_V = weighted_V.sum(dim=2)\n",
    "\n",
    "        # Send output to input dim\n",
    "        weighted_V = weighted_V.flatten(start_dim=2)            # bs, n, dx\n",
    "\n",
    "        # Incorporate y to X\n",
    "        yx1 = self.y_x_add(y).unsqueeze(1)\n",
    "        yx2 = self.y_x_mul(y).unsqueeze(1)\n",
    "        newX = yx1 + (yx2 + 1) * weighted_V\n",
    "\n",
    "        # Output X\n",
    "        newX = self.x_out(newX) * x_mask\n",
    "        diffusion_utils.assert_correctly_masked(newX, x_mask)\n",
    "\n",
    "        # Process y based on X axnd E\n",
    "        y = self.y_y(y)\n",
    "        e_y = self.e_y(E)\n",
    "        x_y = self.x_y(X)\n",
    "        new_y = y + x_y + e_y\n",
    "        new_y = self.y_out(new_y)               # bs, dy\n",
    "\n",
    "        return newX, newE, new_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    n_layers : int -- number of layers\n",
    "    dims : dict -- contains dimensions for each feature type\n",
    "    \"\"\"\n",
    "    def __init__(self, n_layers: int, input_dims: dict, hidden_mlp_dims: dict, hidden_dims: dict,\n",
    "                 output_dims: dict, act_fn_in: nn.ReLU(), act_fn_out: nn.ReLU()):\n",
    "        super().__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.out_dim_X = output_dims['X']\n",
    "        self.out_dim_E = output_dims['E']\n",
    "        self.out_dim_y = output_dims['y']\n",
    "\n",
    "        self.mlp_in_X = nn.Sequential(nn.Linear(input_dims['X'], hidden_mlp_dims['X']), act_fn_in,\n",
    "                                      nn.Linear(hidden_mlp_dims['X'], hidden_dims['dx']), act_fn_in)\n",
    "\n",
    "        self.mlp_in_E = nn.Sequential(nn.Linear(input_dims['E'], hidden_mlp_dims['E']), act_fn_in,\n",
    "                                      nn.Linear(hidden_mlp_dims['E'], hidden_dims['de']), act_fn_in)\n",
    "\n",
    "        self.mlp_in_y = nn.Sequential(nn.Linear(input_dims['y'], hidden_mlp_dims['y']), act_fn_in,\n",
    "                                      nn.Linear(hidden_mlp_dims['y'], hidden_dims['dy']), act_fn_in)\n",
    "\n",
    "        self.tf_layers = nn.ModuleList([XEyTransformerLayer(dx=hidden_dims['dx'],\n",
    "                                                            de=hidden_dims['de'],\n",
    "                                                            dy=hidden_dims['dy'],\n",
    "                                                            n_head=hidden_dims['n_head'],\n",
    "                                                            dim_ffX=hidden_dims['dim_ffX'],\n",
    "                                                            dim_ffE=hidden_dims['dim_ffE'])\n",
    "                                        for i in range(n_layers)])\n",
    "\n",
    "        self.mlp_out_X = nn.Sequential(nn.Linear(hidden_dims['dx'], hidden_mlp_dims['X']), act_fn_out,\n",
    "                                       nn.Linear(hidden_mlp_dims['X'], output_dims['X']))\n",
    "\n",
    "        self.mlp_out_E = nn.Sequential(nn.Linear(hidden_dims['de'], hidden_mlp_dims['E']), act_fn_out,\n",
    "                                       nn.Linear(hidden_mlp_dims['E'], output_dims['E']))\n",
    "\n",
    "        self.mlp_out_y = nn.Sequential(nn.Linear(hidden_dims['dy'], hidden_mlp_dims['y']), act_fn_out,\n",
    "                                       nn.Linear(hidden_mlp_dims['y'], output_dims['y']))\n",
    "\n",
    "    def forward(self, X, E, y, node_mask):\n",
    "        bs, n = X.shape[0], X.shape[1]\n",
    "\n",
    "        diag_mask = torch.eye(n)\n",
    "        diag_mask = ~diag_mask.type_as(E).bool()\n",
    "        diag_mask = diag_mask.unsqueeze(0).unsqueeze(-1).expand(bs, -1, -1, -1)\n",
    "\n",
    "        X_to_out = X[..., :self.out_dim_X]\n",
    "        E_to_out = E[..., :self.out_dim_E]\n",
    "        y_to_out = y[..., :self.out_dim_y]\n",
    "\n",
    "        new_E = self.mlp_in_E(E)\n",
    "        new_E = (new_E + new_E.transpose(1, 2)) / 2\n",
    "        logging.debug(f\"X shape: {X.shape}\")\n",
    "        after_in = utils.PlaceHolder(X=self.mlp_in_X(X), E=new_E, y=self.mlp_in_y(y)).mask(node_mask)\n",
    "        logging.debug(f\"after_in.X shape: {after_in.X.shape}\")\n",
    "        X, E, y = after_in.X, after_in.E, after_in.y\n",
    "\n",
    "        for layer in self.tf_layers:\n",
    "            X, E, y = layer(X, E, y, node_mask)\n",
    "\n",
    "        X = self.mlp_out_X(X)\n",
    "        E = self.mlp_out_E(E)\n",
    "        y = self.mlp_out_y(y)\n",
    "\n",
    "        X = (X + X_to_out)\n",
    "        E = (E + E_to_out) * diag_mask\n",
    "        y = y + y_to_out\n",
    "\n",
    "        E = 1/2 * (E + torch.transpose(E, 1, 2))\n",
    "\n",
    "        return utils.PlaceHolder(X=X, E=E, y=y).mask(node_mask)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gad_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
